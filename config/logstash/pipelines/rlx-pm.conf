# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  tcp {
    port => 5045
    type => "pricemaker_productive"
  }
}

filter {
	grok {
    patterns_dir => ["./config/patterns"]
		match => { "message" => "%{START_ROW} ?(%{ERROR_MESSAGE}|%{INPUT_HTTP}|%{TOTAL_TIME})*" }
	}
  mutate {
    gsub => ["ind_HH", "24","00"]
    add_field => { "data_indian" => "%{ind_D}:%{ind_HH}:%{ind_mm}%{ind_S}"}
    remove_field => ["ind_D", "ind_HH", "ind_mm", "ind_S"]
  }
	date {
		match => ["data_indian","D':'HH':'mm':'ss':'SSS"]
		target => "@timestamp"
    timezone => "Europe/Moscow"
		remove_field => "data_indian"
	}
  kv {
    source => "httpparametrs"
    field_split => ", "
  }
  mutate {
    convert => {"time_taken" => "integer"}
    remove_field => [ "[agent][id]","[agent][hostname]","[agent][type]","[agent][version]","[agent][ephemeral_id]","[input][type]","[ecs][version]" ]
      }
}

output {
  elasticsearch {
    hosts => ["https://elastic.#ENVIRONMENT.nglm.rt.ru:443"]
    #index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    user => "#LOGSTASH_USER"
    password => "#LOGSTASH_PASSWORD"
    ssl => false
    ssl_certificate_verification => false
  }
}
