# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
    type => "pricemaker_productive_debug"
  }
}


filter {
	grok {
    patterns_dir => ["./config/patterns"]
		match => { "message" => "%{START_ROW} ?(%{ERROR_MESSAGE}|%{INPUT_HTTP}|%{TOTAL_TIME})*" }
	}
  mutate {
    gsub => ["ind_HH", "24","00"]
    add_field => { "data_indian" => "%{ind_D}:%{ind_HH}:%{ind_mm}%{ind_S}"}
    remove_field => ["ind_D", "ind_HH", "ind_mm", "ind_S"]
  }
	date {
		match => ["data_indian","D':'HH':'mm':'ss':'SSS"]
		target => "@timestamp"
    timezone => "Europe/Moscow"
		remove_field => "data_indian"
	}
  kv {
    source => "httpparametrs"
    field_split => ", "
  }
  mutate {
    convert => {"time_taken" => "integer"}
    remove_field => [ "[agent][id]","[agent][hostname]","[agent][type]","[agent][version]","[agent][ephemeral_id]","[input][type]","[ecs][version]" ]
      }
}

output {
  stdout {
    codec => rubydebug
  }
}
